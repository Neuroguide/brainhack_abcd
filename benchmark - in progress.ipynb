{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from utils.data_loader import Dataset\n",
    "from utils.helpers import * \n",
    "\n",
    "from sklearn.svm import SVR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "1. create a benchmark for comparing the results \n",
    "2. measure the importance of features based on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filenames = ['./data/cc_training_v2.csv', './data/training_fluid_intelligenceV1.csv', './data/btsv01.txt', \\\n",
    "                     'data/training_data_means.csv', 'data/training_data_entropy.csv',  'data/training_data_stdevs.csv',]\n",
    "validation_filenames=['./data/cc_validation_v2.csv', './data/validation_fluid_intelligenceV1.csv', './data/btsv01.txt', \\\n",
    "                     'data/validation_data_means.csv', 'data/validation_data_entropy.csv', 'data/validation_data_stdevs.csv']\n",
    "\n",
    "cols_to_drop = ['btsv01_id', 'interview_date', 'collection_id', 'dataset_id', 'collection_title', \\\n",
    "                'src_subject_id', 'gender']\n",
    "\n",
    "label_col = 'residual_fluid_intelligence_score'\n",
    "\n",
    "# training = Dataset(training_filenames, cols_to_drop, label_col)\n",
    "# validation = Dataset(validation_filenames, cols_to_drop, label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_columns = []\n",
    "#here we generate custom columns - most of them rely on calculating ratios, so we will provide a function based on that \n",
    "\n",
    "#here we append to our existing train data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here think about how we will benchmark the data\n",
    "models = {\n",
    "    'majority': [np.mean(train_data) for x in train_data], \n",
    "    'random': np.random.rand(len(train_data))*15, #15 is a sd of our distribution\n",
    "    'svr': SVR(),\n",
    "    'randfor': RandomForestRegressor(), \n",
    "    'xgboost': XGBoostRegressor()\n",
    "}\n",
    "#list - each element is an object of a model that we want to try\n",
    "\n",
    "\n",
    "def restrict_dataset(df, df_dict, *filenames):\n",
    "    #here we restrict our dataset to only columns that are found in the dataframes from the following filenames\n",
    "    valid_cols = []\n",
    "    for file in filenames:\n",
    "        valid_cols.append(df_dict[file]['columns'])\n",
    "    valid_cols = set(df.columns).intersection(set(valid_cols))\n",
    "    return df[[valid_cols]]\n",
    "\n",
    "\n",
    "#here we will plot the results for each combination of features \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
